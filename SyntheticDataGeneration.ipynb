{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start time</th>\n",
       "      <th>End time</th>\n",
       "      <th>ID</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-02-25 00:22:46</td>\n",
       "      <td>2008-02-25 09:34:12</td>\n",
       "      <td>10</td>\n",
       "      <td>551.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-02-25 09:37:17</td>\n",
       "      <td>2008-02-25 09:38:02</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-02-25 09:49:23</td>\n",
       "      <td>2008-02-25 09:53:28</td>\n",
       "      <td>13</td>\n",
       "      <td>4.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-02-25 10:02:28</td>\n",
       "      <td>2008-02-25 10:12:42</td>\n",
       "      <td>5</td>\n",
       "      <td>10.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-02-25 10:19:06</td>\n",
       "      <td>2008-02-25 16:55:38</td>\n",
       "      <td>1</td>\n",
       "      <td>396.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Start time            End time  ID    Duration\n",
       "0 2008-02-25 00:22:46 2008-02-25 09:34:12  10  551.433333\n",
       "1 2008-02-25 09:37:17 2008-02-25 09:38:02   4    0.750000\n",
       "2 2008-02-25 09:49:23 2008-02-25 09:53:28  13    4.083333\n",
       "3 2008-02-25 10:02:28 2008-02-25 10:12:42   5   10.233333\n",
       "4 2008-02-25 10:19:06 2008-02-25 16:55:38   1  396.533333"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preparation\n",
    "# --------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/e16011413/OneDrive - Ulster University/Desktop/UCAmI/UCAmI Anomaly/Data/kasterenActData.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Convert start and end times to datetime objects\n",
    "data['Start time'] = pd.to_datetime(data['Start time'])\n",
    "data['End time'] = pd.to_datetime(data['End time'])\n",
    "\n",
    "# Calculate the duration in minutes\n",
    "data['Duration'] = (data['End time'] - data['Start time']).dt.total_seconds() / 60\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {4: 0.9583333333333334, 13: 0.041666666666666664},\n",
       " 4: {13: 0.15789473684210525,\n",
       "  17: 0.06140350877192982,\n",
       "  15: 0.05263157894736842,\n",
       "  10: 0.19298245614035087,\n",
       "  4: 0.3508771929824561,\n",
       "  5: 0.08771929824561403,\n",
       "  1: 0.09649122807017543},\n",
       " 13: {5: 0.55, 4: 0.4, 17: 0.05},\n",
       " 5: {1: 0.9130434782608695, 15: 0.043478260869565216, 4: 0.043478260869565216},\n",
       " 1: {4: 0.696969696969697,\n",
       "  15: 0.09090909090909091,\n",
       "  1: 0.030303030303030304,\n",
       "  17: 0.09090909090909091,\n",
       "  10: 0.030303030303030304,\n",
       "  5: 0.06060606060606061},\n",
       " 17: {4: 0.8, 17: 0.15, 13: 0.05},\n",
       " 15: {17: 0.6, 1: 0.1, 4: 0.3}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transition Matrix Calculation\n",
    "# ----------------------------------\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Extract the activities and compute transitions\n",
    "activities = data['ID']\n",
    "transitions = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Count transitions\n",
    "for (a1, a2) in zip(activities[:-1], activities[1:]):\n",
    "    transitions[a1][a2] += 1\n",
    "\n",
    "# Compute probabilities\n",
    "transition_probabilities = {}\n",
    "for a1, a2_dict in transitions.items():\n",
    "    total = float(sum(a2_dict.values()))\n",
    "    transition_probabilities[a1] = {a2: count / total for a2, count in a2_dict.items()}\n",
    "\n",
    "# Display the transition probabilities\n",
    "transition_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': {'B': 0.25, 'A': 0.5, 'C': 0.25},\n",
       " 'B': {'A': 1.0},\n",
       " 'C': {'D': 1.0},\n",
       " 'D': {'A': 1.0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "activities = ['A', 'B', 'A', 'A', 'C', 'D', 'A', 'A']\n",
    "transitions = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Count transitions\n",
    "for (a1, a2) in zip(activities[:-1], activities[1:]):\n",
    "    transitions[a1][a2] += 1\n",
    "\n",
    "# Compute probabilities\n",
    "transition_probabilities = {}\n",
    "for a1, a2_dict in transitions.items():\n",
    "    total = float(sum(a2_dict.values()))\n",
    "    transition_probabilities[a1] = {a2: count / total for a2, count in a2_dict.items()}\n",
    "\n",
    "# Display the transition probabilities\n",
    "transition_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "4     0.875000\n",
       "10    0.083333\n",
       "17    0.041667\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Activity Determination (This helps us to know by which activities we better begin the synthetic days)\n",
    "# ----------------------------------\n",
    "# Find unique days and their first activities\n",
    "data['Date'] = pd.to_datetime(data['Start time']).dt.date\n",
    "first_activities = data.groupby('Date').first()['ID']\n",
    "\n",
    "# Count the occurrences of each first activity\n",
    "first_activity_counts = first_activities.value_counts()\n",
    "first_activity_probabilities = first_activity_counts / len(first_activities)\n",
    "\n",
    "# Display the probabilities for the first activity\n",
    "first_activity_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fit for Activity 1: exponential with params (40.766666666666666, 622.9514705882352, -372.66819089744394)\n",
      "Best fit for Activity 4: weibull with params (0.7177705629367819, 0.5333333333333332, 0.7653271511120208, -inf)\n",
      "Best fit for Activity 5: exponential with params (2.6, 6.9565217391304355, -139.72899775037803)\n",
      "Best fit for Activity 10: weibull with params (0.2120821295060068, 23.799999999999997, 3.7994096740934964, -266.95924230638576)\n",
      "Best fit for Activity 13: lognorm with params (1.2384198317738446, 1.1651303232987713, 1.1442546898327788, -95.26521087329502)\n",
      "Best fit for Activity 15: invgauss with params (0.4116101499519757, 2.349378894785014, 77.46152745346008, -64.86965423314555)\n",
      "Best fit for Activity 17: exponential with params (0.15, 0.7374999999999998, -73.82486165571657)\n"
     ]
    }
   ],
   "source": [
    "# Fitting the Best Distribution for Each Activity \n",
    "#------------------------------------------------------\n",
    "from scipy.stats import lognorm, expon, weibull_min, invgauss\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def fit_distributions(durations, max_components=3):\n",
    "    results = {}\n",
    "    \n",
    "    durations_log = np.log(durations).reshape(-1, 1)\n",
    "    \n",
    "    # Gaussian Mixture Model with Gamma\n",
    "    best_bic = np.inf\n",
    "    best_gmm = None\n",
    "    best_n_components = 2\n",
    "\n",
    "    for n_components in range(1, max_components + 1):\n",
    "        gmm = GaussianMixture(n_components=n_components)\n",
    "        gmm.fit(durations_log)\n",
    "        bic = gmm.bic(durations_log)\n",
    "        if bic < best_bic:\n",
    "            best_bic = bic\n",
    "            best_gmm = gmm\n",
    "            best_n_components = n_components\n",
    "    \n",
    "    weights = best_gmm.weights_\n",
    "    means = np.exp(best_gmm.means_).flatten()\n",
    "    variances = (np.exp(best_gmm.covariances_).flatten())**0.5\n",
    "    shapes = (means / variances)**2\n",
    "    scales = variances**2 / means\n",
    "    \n",
    "    results['gamma_mixture'] = (weights, shapes, scales, best_n_components, best_bic)\n",
    "\n",
    "    # Log-normal distribution\n",
    "    lognorm_params = lognorm.fit(durations)\n",
    "    lognorm_bic = np.sum(lognorm.logpdf(durations, *lognorm_params)) - len(durations) * np.log(len(durations))\n",
    "    results['lognorm'] = lognorm_params + (lognorm_bic,)\n",
    "\n",
    "    # Exponential distribution\n",
    "    expon_params = expon.fit(durations)\n",
    "    expon_bic = np.sum(expon.logpdf(durations, *expon_params)) - len(durations) * np.log(len(durations))\n",
    "    results['exponential'] = expon_params + (expon_bic,)\n",
    "\n",
    "    # Weibull distribution\n",
    "    weibull_params = weibull_min.fit(durations)\n",
    "    weibull_bic = np.sum(weibull_min.logpdf(durations, *weibull_params)) - len(durations) * np.log(len(durations))\n",
    "    results['weibull'] = weibull_params + (weibull_bic,)\n",
    "\n",
    "    # Inverse Gaussian distribution\n",
    "    invgauss_params = invgauss.fit(durations)\n",
    "    invgauss_bic = np.sum(invgauss.logpdf(durations, *invgauss_params)) - len(durations) * np.log(len(durations))\n",
    "    results['invgauss'] = invgauss_params + (invgauss_bic,)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Fit distributions for each activity\n",
    "duration_distributions = {}\n",
    "durations = data.groupby('ID')['Duration'].apply(list)\n",
    "\n",
    "for activity, duration_list in durations.items():\n",
    "    distributions = fit_distributions(np.array(duration_list))\n",
    "    duration_distributions[activity] = distributions\n",
    "\n",
    "\n",
    "# Select the best fitting distribution for each activity\n",
    "best_fit_distributions = {}\n",
    "\n",
    "for activity, distributions in duration_distributions.items():\n",
    "    best_bic = np.inf\n",
    "    best_distribution = None\n",
    "    \n",
    "    for dist_name, params in distributions.items():\n",
    "        if params[-1] < best_bic:\n",
    "            best_bic = params[-1]\n",
    "            best_distribution = (dist_name, params)\n",
    "    \n",
    "    best_fit_distributions[activity] = best_distribution\n",
    "\n",
    "\n",
    "# Function to plot the fitted distributions\n",
    "def plot_fitted_distribution(activity, duration_list, dist_name, params, file_path):\n",
    "    sns.histplot(duration_list, bins=50, kde=True, stat='density', label='Observed Data', color='skyblue')\n",
    "    \n",
    "    x = np.linspace(min(duration_list), max(duration_list), 1000)\n",
    "    \n",
    "    if dist_name == 'gamma_mixture':\n",
    "        weights, shapes, scales, best_n_components, _ = params\n",
    "        y = np.zeros_like(x)\n",
    "        for weight, shape, scale in zip(weights, shapes, scales):\n",
    "            y += weight * gamma.pdf(x, shape, scale=scale)\n",
    "        plt.plot(x, y, label='Fitted Gamma Mixture', color='red')\n",
    "    \n",
    "    elif dist_name == 'lognorm':\n",
    "        shape, loc, scale, _ = params\n",
    "        y = lognorm.pdf(x, shape, loc, scale)\n",
    "        plt.plot(x, y, label='Fitted Log-Normal', color='red')\n",
    "    \n",
    "    elif dist_name == 'exponential':\n",
    "        loc, scale, _ = params\n",
    "        y = expon.pdf(x, loc, scale)\n",
    "        plt.plot(x, y, label='Fitted Exponential', color='red')\n",
    "    \n",
    "    elif dist_name == 'weibull':\n",
    "        shape, loc, scale, _ = params\n",
    "        y = weibull_min.pdf(x, shape, loc, scale)\n",
    "        plt.plot(x, y, label='Fitted Weibull', color='red')\n",
    "    \n",
    "    elif dist_name == 'invgauss':\n",
    "        mu, loc, scale, _ = params\n",
    "        y = invgauss.pdf(x, mu, loc, scale)\n",
    "        plt.plot(x, y, label='Fitted Inverse Gaussian', color='red')\n",
    "    \n",
    "    plt.title(f'Activity: {activity}')\n",
    "    plt.xlabel('Duration (minutes)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(file_path, f'{activity}_fitted_distribution.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Plot and save the best-fitting distributions for each activity\n",
    "file_path = 'C:/Users/e16011413/OneDrive - Ulster University/Desktop/UCAmI/UCAmI Anomaly/SyntheticData'\n",
    "for activity, duration_list in durations.items():\n",
    "    dist_name, params = best_fit_distributions[activity]\n",
    "    plot_fitted_distribution(activity, duration_list, dist_name, params, file_path)\n",
    "\n",
    "\n",
    "# Print out the fitted distributions\n",
    "best_fit_distributions = {}\n",
    "\n",
    "for activity, distributions in duration_distributions.items():\n",
    "    best_bic = np.inf\n",
    "    best_distribution = None\n",
    "    \n",
    "    for dist_name, params in distributions.items():\n",
    "        if params[-1] < best_bic:\n",
    "            best_bic = params[-1]\n",
    "            best_distribution = (dist_name, params)\n",
    "    \n",
    "    best_fit_distributions[activity] = best_distribution\n",
    "\n",
    "# Save best fitting distributions to a text file\n",
    "text_file_path = os.path.join(file_path, 'best_fit_distributions.txt')\n",
    "with open(text_file_path, 'w') as file:\n",
    "    for activity, (dist_name, params) in best_fit_distributions.items():\n",
    "        file.write(f\"Best fit for Activity {activity}: {dist_name} with params {params}\\n\")\n",
    "\n",
    "\n",
    "# Print best fitting distributions for each activity\n",
    "for activity, (dist_name, params) in best_fit_distributions.items():\n",
    "    print(f\"Best fit for Activity {activity}: {dist_name} with params {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([4, 4, 10, 4, 1, 4, 4, 10, 4], [1, 1, 23.80004911797008, 1, 202.0288870678084, 1.8063785112579558, 1, 25.855322982901377, 1.2898645829176476])\n",
      "([4, 4, 5, 1, 4, 5, 1, 4, 4, 4], [1.692709878869606, 1.5026035101794764, 5.317399698016523, 646.0030097623886, 1.5457391344186042, 7.829042927391299, 308.5305606299302, 1.4233024211755785, 1, 1])\n",
      "([4, 17, 4, 5, 1, 4, 4, 1, 17, 13], [1, 1, 1.1554160049104478, 3.426819705542867, 586.5749992748378, 1.3353036147903605, 1, 504.4859736769278, 1, 1.7077427638617702])\n",
      "([4, 15, 17, 4, 5, 4, 13, 4, 10, 4], [1.065756249900661, 18.084417441333468, 1.8481435289519692, 1, 14.67547753049126, 2.760514085930049, 1.526607541519878, 1.0944945967591884, 36.133854574134446, 1])\n"
     ]
    }
   ],
   "source": [
    "# Generation of Synthetic Data\n",
    "# ---------------------------------\n",
    "# ---------------------------------\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import gamma, lognorm, expon, weibull_min, invgauss\n",
    "\n",
    "def generate_synthetic_duration(dist_name, params):\n",
    "    \"\"\"\n",
    "    Generate a synthetic duration based on the specified distribution.\n",
    "    \"\"\"\n",
    "    if dist_name == 'gamma_mixture':\n",
    "        weights, shapes, scales, best_n_components, _ = params\n",
    "        # Randomly choose a component based on weights\n",
    "        component = np.random.choice(best_n_components, p=weights)\n",
    "        shape = shapes[component]\n",
    "        scale = scales[component]\n",
    "        duration = gamma.rvs(shape, scale=scale)\n",
    "        \n",
    "    elif dist_name == 'lognorm':\n",
    "        shape, loc, scale, _ = params\n",
    "        duration = lognorm.rvs(shape, loc=loc, scale=scale)\n",
    "        \n",
    "    elif dist_name == 'exponential':\n",
    "        loc, scale, _ = params\n",
    "        duration = expon.rvs(loc=loc, scale=scale)\n",
    "        \n",
    "    elif dist_name == 'weibull':\n",
    "        shape, loc, scale, _ = params\n",
    "        duration = weibull_min.rvs(shape, loc=loc, scale=scale)\n",
    "        \n",
    "    elif dist_name == 'invgauss':\n",
    "        mu, loc, scale, _ = params\n",
    "        duration = invgauss.rvs(mu, loc=loc, scale=scale)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported distribution: {dist_name}\")\n",
    "        \n",
    "    return duration\n",
    "\n",
    "def generate_synthetic_day(transition_probabilities, first_activity_probabilities, duration_distributions):\n",
    "    while True:\n",
    "        synthetic_day = []\n",
    "        \n",
    "        # Generate the first activity\n",
    "        first_activity = random.choices(\n",
    "            list(first_activity_probabilities.index), \n",
    "            weights=first_activity_probabilities.values\n",
    "        )[0]\n",
    "        synthetic_day.append(first_activity)\n",
    "        \n",
    "        current_activity = first_activity\n",
    "        steps = 0\n",
    "        max_steps = 1000  # Avoid potential infinite loops\n",
    "        min_activities = 9\n",
    "        max_activities = 11\n",
    "        num_activities = np.random.randint(min_activities, max_activities + 1)\n",
    "        \n",
    "        while steps < max_steps and len(synthetic_day) < num_activities:\n",
    "            next_activities = list(transition_probabilities[current_activity].keys())\n",
    "            next_probabilities = list(transition_probabilities[current_activity].values())\n",
    "            next_activity = random.choices(next_activities, weights=next_probabilities)[0]\n",
    "            \n",
    "            if next_activity == 'end':\n",
    "                break\n",
    "            \n",
    "            synthetic_day.append(next_activity)\n",
    "            current_activity = next_activity\n",
    "            steps += 1\n",
    "        \n",
    "        synthetic_durations = [\n",
    "            max(1, generate_synthetic_duration(*duration_distributions[activity]))  # Use the best-fitting parameters\n",
    "            for activity in synthetic_day\n",
    "        ]\n",
    "        \n",
    "        # Ensure the total duration does not exceed 1440 minutes\n",
    "        total_duration = sum(synthetic_durations)\n",
    "        while total_duration > 1440 and len(synthetic_day) > 2:\n",
    "            # Remove a random activity, except for activities labeled 1 or 10\n",
    "            removable_indices = [i for i, activity in enumerate(synthetic_day) if activity not in [1, 10]]\n",
    "            if removable_indices:\n",
    "                remove_index = random.choice(removable_indices)\n",
    "                synthetic_day.pop(remove_index)\n",
    "                synthetic_durations.pop(remove_index)\n",
    "                total_duration = sum(synthetic_durations)\n",
    "            else:\n",
    "                break  # Break the loop if no removable activities are found\n",
    "        \n",
    "        # If the total duration is less than or equal to 1440, return the synthetic day\n",
    "        if total_duration <= 1440:\n",
    "            return synthetic_day, synthetic_durations\n",
    "\n",
    "# Example usage\n",
    "# Assuming transition_probabilities, first_activity_probabilities, and duration_distributions are defined\n",
    "\n",
    "# Generate synthetic days\n",
    "num_synthetic_days = 10000\n",
    "synthetic_days = [generate_synthetic_day(transition_probabilities, first_activity_probabilities, best_fit_distributions) for _ in range(num_synthetic_days)]\n",
    "\n",
    "# Print the first synthetic day\n",
    "print(synthetic_days[0])\n",
    "print(synthetic_days[1])\n",
    "print(synthetic_days[2])\n",
    "print(synthetic_days[3])\n",
    "\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "# Create a workbook\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.active\n",
    "\n",
    "# Set the column headers\n",
    "sheet.cell(row=1, column=1).value = \"Day\"\n",
    "sheet.cell(row=1, column=2).value = \"Activities\"\n",
    "sheet.cell(row=1, column=3).value = \"Durations\"\n",
    "\n",
    "# Write the synthetic data\n",
    "for i, day in enumerate(synthetic_days):\n",
    "    sheet.cell(row=i+2, column=1).value = i+1  # Start day numbering from 1\n",
    "    sheet.cell(row=i+2, column=2).value = str(day[0])  # Insert the whole list of activities\n",
    "    sheet.cell(row=i+2, column=3).value = str(day[1])  # Insert the whole list of durations\n",
    "\n",
    "# Save the workbook\n",
    "FilePath = 'C:/Users/e16011413/OneDrive - Ulster University/Desktop/UCAmI/UCAmI Anomaly/SyntheticData/synthetic_data.xlsx'\n",
    "wb.save(FilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sequence Similarity: 0.9002668965905943\n",
      "Duration Distribution P-Values: [7.369035028118557e-19, 4.425939728548843e-15, 0.8331416981234763, 0.002657831801605838, 0.03115927059642961, 8.019194646686809e-17, 0.9083686330624022]\n",
      "Transition Matrix Difference: 0.12217815741992558\n"
     ]
    }
   ],
   "source": [
    "# Conformance Test on three aspects: 1- Activity Sequence   ,  2- Duration Distribution  ,   3- Transition Probability\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Activity Sequence Comparison\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def sequence_similarity(seq1, seq2):\n",
    "    return SequenceMatcher(None, seq1, seq2).ratio()\n",
    "\n",
    "def average_sequence_similarity(real_days, synthetic_days):\n",
    "    similarities = []\n",
    "    for real_day in real_days:\n",
    "        best_similarity = max(sequence_similarity(real_day, synthetic_day[0]) for synthetic_day in synthetic_days)\n",
    "        similarities.append(best_similarity)\n",
    "    return sum(similarities) / len(similarities)\n",
    "\n",
    "# Duration Distribution Comparison\n",
    "# --------------------------------\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "def compare_duration_distributions(real_durations, synthetic_durations):\n",
    "    p_values = []\n",
    "    for activity in real_durations.keys():\n",
    "        real_duration = real_durations[activity]\n",
    "        synthetic_duration = synthetic_durations.get(activity, [])\n",
    "        if synthetic_duration:\n",
    "            _, p_value = ks_2samp(real_duration, synthetic_duration)\n",
    "            p_values.append(p_value)\n",
    "    return p_values\n",
    "\n",
    "# Transition Probability Matrix Comparison\n",
    "# ----------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "def compute_transition_matrix(days):\n",
    "    activities = set(activity for day in days for activity in day)\n",
    "    activity_index = {activity: i for i, activity in enumerate(activities)}\n",
    "    n = len(activities)\n",
    "    transition_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for day in days:\n",
    "        for i in range(len(day) - 1):\n",
    "            current_activity = day[i]\n",
    "            next_activity = day[i + 1]\n",
    "            transition_matrix[activity_index[current_activity], activity_index[next_activity]] += 1\n",
    "    \n",
    "    transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "    return transition_matrix, activity_index\n",
    "\n",
    "def compare_transition_matrices(real_matrix, synthetic_matrix):\n",
    "    return np.linalg.norm(real_matrix - synthetic_matrix)\n",
    "\n",
    "# Perform Conformance Checking\n",
    "# ----------------------------------------\n",
    "# ----------------------------------------\n",
    "\n",
    "# Assuming real_days is a list of lists where each sublist is a sequence of activities for a day in the real dataset\n",
    "real_days = [list(data.loc[data['Date'] == day, 'ID']) for day in data['Date'].unique()]\n",
    "\n",
    "# Convert real data to a format comparable to synthetic data\n",
    "real_durations = {activity: data[data['ID'] == activity]['Duration'].tolist() for activity in data['ID'].unique()}\n",
    "\n",
    "# Generate transition matrices for real and synthetic data\n",
    "real_transition_matrix, real_activity_index = compute_transition_matrix(real_days)\n",
    "synthetic_transition_matrix, synthetic_activity_index = compute_transition_matrix([synthetic_day[0] for synthetic_day in synthetic_days])\n",
    "\n",
    "# Align synthetic activity index with real activity index\n",
    "aligned_synthetic_transition_matrix = np.zeros_like(real_transition_matrix)\n",
    "for activity, index in real_activity_index.items():\n",
    "    if activity in synthetic_activity_index:\n",
    "        aligned_synthetic_transition_matrix[index] = synthetic_transition_matrix[synthetic_activity_index[activity]]\n",
    "\n",
    "# Perform comparisons\n",
    "sequence_similarity_score = average_sequence_similarity(real_days, synthetic_days)\n",
    "duration_p_values = compare_duration_distributions(real_durations, {activity: [duration for day, durations in synthetic_days for a, duration in zip(day, durations) if a == activity] for activity in real_durations.keys()})\n",
    "transition_matrix_difference = compare_transition_matrices(real_transition_matrix, aligned_synthetic_transition_matrix)\n",
    "\n",
    "# Output results\n",
    "print(f\"Average Sequence Similarity: {sequence_similarity_score}\")\n",
    "print(f\"Duration Distribution P-Values: {duration_p_values}\")\n",
    "print(f\"Transition Matrix Difference: {transition_matrix_difference}\")\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open(\"C:/Users/e16011413/OneDrive - Ulster University/Desktop/UCAmI/UCAmI Anomaly/SyntheticData/ConformanceResults.txt\", \"w\") as f:\n",
    "    f.write(f\"Average Sequence Similarity: {sequence_similarity_score}\\n\")\n",
    "    f.write(f\"Duration Distribution P-Values: {duration_p_values}\\n\")\n",
    "    f.write(f\"Transition Matrix Difference: {transition_matrix_difference}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
